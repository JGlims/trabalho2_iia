{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JGlims/trabalho2_iia/blob/main/C%C3%B3pia_de_Trabalho_IA_Classic_ML_%2B_Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Atividade - Perceptron e MLP com scripts programados com PyTorch**\n",
        "\n",
        "\n",
        "*   **Nome**:\n",
        "*   **Matrícula**:\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "vtymgbhx7z-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Diagnóstico de Diabetes com Redes Neurais**\n",
        "\n",
        "Nesta atividade, vamos trabalhar com um problema aplicado de **classificação binária**: prever se uma pessoa possui ou não diabetes com base em um conjunto de variáveis clínicas.\n",
        "\n",
        "[Pima Indians Diabetes Database](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)\n",
        "\n",
        "---\n",
        "\n",
        "## **Contexto**\n",
        "\n",
        "- O dataset utilizado é o **Pima Indians Diabetes Dataset**, coletado originalmente pelo Instituto Nacional de Diabetes e Doenças Digestivas e Renais dos Estados Unidos.\n",
        "- Ele contém registros de mulheres com pelo menos 21 anos de idade da população Pima, um grupo étnico nativo norte-americano com alta incidência de diabetes tipo 2.\n",
        "\n",
        "## **Objetivo**\n",
        "\n",
        "O objetivo é treinar uma MLP para prever a presença de diabetes a partir de atributos fisiológicos e laboratoriais.\n",
        "\n",
        "## **Variáveis de entrada**\n",
        "\n",
        "Cada observação contém os seguintes atributos:\n",
        "\n",
        "1. **Pregnancies**, number of times pregnant: Variável discreta.\n",
        "2. **Glucose**, plasma glucose concentration after 2 hours in an oral glucose tolerance test: Variável contínua.\n",
        "3. **BloodPressure**, diastolic blood pressure, in mm Hg: Variável contínua.\n",
        "4. **SkinThickness**, triceps skin fold thickness, in mm: Variável contínua.\n",
        "5. **Insulin**, 2-hour serum insulin, in μU/mL: Variável contínua.\n",
        "6. **BMI**, body mass index, weight in kg/(height in m)²: Variável contínua.\n",
        "7. **DiabetesPedigreeFunction**, family history function: Variável contínua.\n",
        "8. **Age**, in years: : Variável discreta.\n",
        "\n",
        "## **Variáveis de saída (Target)**\n",
        "\n",
        "- **Outcome = 1**: Diabetic\n",
        "- **Outcome = 0**: Non-diabetic\n"
      ],
      "metadata": {
        "id": "ZgU7nDVr8kfQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercício 1 - Preparação dos dados**\n",
        "\n",
        "1. Realize tratamento e limpeza de dados caso necessário para treinamento do modelo\n",
        "2. Crie a matriz de correlação das features e extraia pelo menos um insight estatítstico visível na matriz\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# URL do dataset\n",
        "url = \"https://raw.githubusercontent.com/pcbrom/perceptron-mlp-cnn/refs/heads/main/data/diabetes.csv\"\n",
        "\n",
        "# Carregar o dataset\n",
        "df = pd.read_csv(url)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "IJFL-lD674cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Código Exercício 1 ######"
      ],
      "metadata": {
        "id": "7X_LMwR8Ejrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Respostas Exercício 1:\n",
        "\n",
        "insight estatístico sobre os dados a partir da matriz de correlação"
      ],
      "metadata": {
        "id": "m7emN007Es5F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercício 2 — Comparação de Modelos de Classificação**\n",
        "\n",
        "### Objetivo\n",
        "Treinar e comparar dois modelos de classificação supervisionada usando **scikit-learn**:\n",
        "- **DecisionTreeClassifier**\n",
        "- **RandomForestClassifier**\n",
        "\n",
        "O foco é **encontrar a melhor combinação de hiperparâmetros** para cada modelo e **analisar qual apresenta melhor desempenho** nos conjuntos de treino e teste.\n",
        "\n",
        "---\n",
        "\n",
        "###  Instruções\n",
        "\n",
        "1. **Divisão dos dados**\n",
        "   - Utilize o mesmo dataset do Exercício 1 (já limpo e tratado).  \n",
        "   - Divida os dados em **80% para treino** e **20% para teste**, de forma **estratificada** para manter a proporção de classes.  \n",
        "   - Use `train_test_split` do **scikit-learn** com `random_state=42`.\n",
        "\n",
        "2. **Treinamento dos modelos**\n",
        "   - Crie dois modelos e os treine utilizando o **conjunto de treino**:\n",
        "     - `DecisionTreeClassifier`\n",
        "     - `RandomForestClassifier`\n",
        "\n",
        "3. **Busca de hiperparâmetros**\n",
        "   - Utilize **GridSearchCV** para encontrar a melhor combinação de parâmetros para cada modelo.  \n",
        "   - Varie os seguintes parâmetros:\n",
        "     - **Decision Tree** → `max_depth`, `min_samples_split`, `min_samples_leaf`, `criterion`.  \n",
        "     - **Random Forest** → `n_estimators`, `max_depth`, `min_samples_split`, `min_samples_leaf`, `max_features`.\n",
        "\n",
        "4. **Avaliação**\n",
        "   - Avalie os **melhores modelos** (após o GridSearch) usando o **conjunto de teste**.  \n",
        "   - Calcule as métricas:\n",
        "     - **Acurácia**\n",
        "     - **F1-Score**\n",
        "\n",
        "5. **Apresentação dos resultados**\n",
        "   - Monte uma **tabela Markdown** como a seguir:\n",
        "\n",
        "     ```markdown\n",
        "     | Modelo | Conjunto | Acurácia | F1-Score |\n",
        "     |:-------|:----------|----------:|----------:|\n",
        "     | Decision Tree | Treino | 0.0000 | 0.0000 |\n",
        "     | Decision Tree | Teste  | 0.0000 | 0.0000 |\n",
        "     | Random Forest | Treino | 0.0000 | 0.0000 |\n",
        "     | Random Forest | Teste  | 0.0000 | 0.0000 |\n",
        "     ```\n",
        "\n",
        "6. **Análise dos resultados**\n",
        "   - Responda:\n",
        "     - a) Qual modelo obteve melhor desempenho? por quê ?.  \n",
        "     - b) Houve **overfitting**? Como você justificaria a resposta anterior?\n",
        "     - d) Qual modelo se sobressaiu ? Esse resultado era esperado ? Por quê?\n",
        "\n"
      ],
      "metadata": {
        "id": "1c7cNsU_7jhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Código Exercício 2 ######"
      ],
      "metadata": {
        "id": "5KBJCyA7ErAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LYRlOBlyF-Uy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercício 3 - Construção MLP**\n",
        "\n",
        "1. Proponha uma arquiterura de MLP, defina os hiperparâmetros, otimizador, função de perda.\n",
        "2. Faça a divisão dos dados:\n",
        "  - 70% para treino\n",
        "  - 15% para validação\n",
        "  - 15% para teste\n",
        "3. Faça o treinamento da rede e apresente:\n",
        "  - Acurácia no conjunto de teste.\n",
        "  - Matriz de confusão.\n",
        "  - Relatório de classificação.\n",
        "4. Responda:\n",
        "- a) Houve diferença entre o desempenho no conjunto de validação e no conjunto de teste? Como essa diferença deve ser interpretada?\n",
        "- b) Como a validação contribui para construção de um modelo mais estável**\n",
        "- c) Durante o treinamento do seu MLP, qual/quais foram as decisões que mais impactaram o desempenho final do modelo (como número de camadas, taxa de aprendizado, função de ativação ou otimizador)? Reflita sobre como essas escolhas influenciaram o comportamento do erro de treino e validação ao longo das épocas.\n",
        "\n",
        "**O uso de pytorch é obrigatório para resolução**\n",
        "```python\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import seaborn as sns\n",
        "# --- Acurácia\n",
        "acc_test = accuracy_score(y_true_test, y_pred_test)\n",
        "print(f\"Acurácia no conjunto de teste: {acc_test:.4f}\")\n",
        "\n",
        "# --- Matriz de confusão\n",
        "cm = confusion_matrix(y_true_test, y_pred_test)\n",
        "plt.figure(figsize=(4, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Matriz de Confusão (Teste)')\n",
        "plt.xlabel('Classe Predita')\n",
        "plt.ylabel('Classe Real')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Relatório de classificação\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_true_test, y_pred_test, digits=4, zero_division=1))\n",
        "```"
      ],
      "metadata": {
        "id": "tNqjC84X895B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Código Exercício 3 ######"
      ],
      "metadata": {
        "id": "-cABrwkk-pvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Respostas Exercício 3\n",
        "\n",
        "- a)\n",
        "\n",
        "- b)\n",
        "\n",
        "- c)\n"
      ],
      "metadata": {
        "id": "RJrHQRjfFd3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QA\n",
        "\n",
        "1. **Considere um modelo de detecção de fraudes em transações financeiras. Nesse contexto, qual métrica deve ser priorizada — *precision* ou *recall* — e por quê? Justifique com base nos efeitos de falsos positivos e falsos negativos.**  \n",
        "2. **Considere um modelo de triagem médica que identifica pacientes em estado crítico. Nesse caso, qual métrica deve ser priorizada — *precision* ou *recall* — e por quê? Explique os impactos dessa escolha.**  \n",
        "3. **Um modelo de classificação apresenta previsões sistematicamente enviesadas para uma das classes, independentemente dos dados de entrada. O que esse comportamento indica e quais medidas podem ser tomadas para corrigir o problema?**  \n",
        "4. **Durante o treinamento de uma rede neural profunda, as camadas iniciais deixam de atualizar seus pesos, apresentando gradientes próximos de zero. Que fenômeno está ocorrendo, quais são suas causas e quais estratégias podem ser aplicadas para solucioná-lo?**  \n",
        "5. **Um aluno utiliza a função de ativação degrau em todas as camadas de um MLP profundo. Descreva o impacto dessa decisão sobre o processo de aprendizado e compare com o comportamento de uma rede que utiliza a função ReLU.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NKTaC_rK-qG6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Respostas QA\n",
        "\n",
        "- 1)\n",
        "\n",
        "- 2)\n",
        "\n",
        "- 3)\n",
        "\n",
        "- 4)\n",
        "\n",
        "- 5)"
      ],
      "metadata": {
        "id": "89hUVua7FLQ2"
      }
    }
  ]
}